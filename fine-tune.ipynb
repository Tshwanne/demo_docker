{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c8e3d1dc47e49d093673a144961e429":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d84e095d6e7f464aaf588d79893fb012","IPY_MODEL_3bfa4ee055d144b09ca766d19b02c494","IPY_MODEL_75f64f4f11054a8daa2e620fcaace2d1"],"layout":"IPY_MODEL_7d982c016fd0474dbf2d60f9e9fbaae6"}},"3bfa4ee055d144b09ca766d19b02c494":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af9ea502205644deaeda3964146022c0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6db91522b3b54af8ae3ed05566ee0d96","value":0}},"6853d0ec993f4cfbb6ab8cf77e47e79a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6db91522b3b54af8ae3ed05566ee0d96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75f64f4f11054a8daa2e620fcaace2d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec21f525cf234813bd6f5eff244d3aae","placeholder":"​","style":"IPY_MODEL_6853d0ec993f4cfbb6ab8cf77e47e79a","value":" 0/0 [00:00&lt;?, ?it/s]"}},"7ae39b6612114f5bb2be2b448ddf62c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d982c016fd0474dbf2d60f9e9fbaae6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af9ea502205644deaeda3964146022c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cb67c1e38b544ff48a811de138f16d6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d84e095d6e7f464aaf588d79893fb012":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ae39b6612114f5bb2be2b448ddf62c3","placeholder":"​","style":"IPY_MODEL_cb67c1e38b544ff48a811de138f16d6b","value":""}},"ec21f525cf234813bd6f5eff244d3aae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport shutil\nimport re\nfrom datetime import datetime\n\nbase_dir = os.path.join(os.getcwd(),'dreambooth_training')\nauth_json_path = os.path.join(base_dir, 'auth.json')\n\ninstance_basename = 'instance_images'\nclass_basename = 'class_images'\ninstance_dir = os.path.join(base_dir, instance_basename)\nclass_dir = os.path.join(base_dir, class_basename)\nmodel_output_dir = os.path.join(base_dir, 'model_output')\nimg_output_dir = os.path.join(base_dir, \"images_output\")\ntemp_img_folder = os.path.join(img_output_dir,\"temp\")\nckpt_output = os.path.join(base_dir, \"ckpt_output\")\nmodel_output_image_folder = os.path.join(model_output_dir,\"images\")\nmodel_output_ckpt_folder = os.path.join(model_output_dir,\"checkpoints\")\n\ngdrive_working_dir = \"training data\"\ng_class_images__folder_id = \"1CCrJyVBztuMHCbQq5Bra18xfi6-BLfYJ\"\napp_parent_id = '1C1UpIatKFnXlvb-RAUCp5Apehe49i9Zm'\ngdrive_img_output_dir = \"1GjyMUZm9slxAlCiMbQAKm0sglK6xlFTQ\"\ngdrive_ckpt_output_dir = \"1JWfR99FufTqZF00LuVuhT8vg8fxKMXfu\"\nunzip_dir = os.path.join(base_dir, 'output')\ngdrive_models_output_dir = \"1JX6QjTqzB1MsJgjYAeMTvzh0F2y68ObT\"\n\nsubject_class = \"woman\"\nmodel_id = \"Taa97/ZeroCool94_SDv1-5\"\n#regulation_parent_path = os.path.join(base_dir, 'stable-diffusion-regularization-images')\n#classes_path = os.path.join(regulation_parent_path, model)\n\n\ntoken = \"sks\"\ninstance_prompt = f\"photo of a {token} {subject_class}\"\nclass_prompt = f\"photo of a {subject_class}\"\n\n\n# Dictionary with clusters of images needed and number for each cluster\nneeded_images = {\n \"selfies\": 1,\n  \"full_body\": 0,\n  \"half_body\": 0,\n  \"bad_pics\":0,\n  \"same_fanana_1\":0,\n  \"same_fanana_2\":0,\n  \"same_fanana_3\":0,\n\n}\n\n\ncluster_ids = {\n  \"selfies\": \"1E_imzMbg2ENmUoNUoknJiLLvrzq5nOfZ\",\n  \"subject_parent_folder\":\"1DWihpWZj1SeuGTsL1TMBBpfgJXAWl-BS\",\n  \"full_body\": \"1EboU_KrwXd1cjTBlIAN7_XEy0EwslFsQ\",\n  \"half_body\": \"1Ec6sASK2O8zHUJDRxoWMsp7Y0Dej15v8\",\n  \"bad_pics\":\"1Ec7LsRWQNpkeeOsDtzeAuoVf7hYZ43TM\",\n  \"same_fanana_1\":\"1EgKOSt7zQojeg9JiRXHZVIl3ff5fETnD\",\n  \"same_fanana_2\":\"1EgOoirUEcPgMQgWz6_i3MuKcI2FInAXp\",\n  \"same_fanana_3\":\"1Fw81CvruCX6BnB9xX2G9HnOz4Dddg7U8\",\n\n}\n\n# Create directories\nfor dir_path in [base_dir, instance_dir, class_dir, model_output_dir,img_output_dir, temp_img_folder,ckpt_output ]:\n    if os.path.exists(dir_path):\n        shutil.rmtree(dir_path)\n\n    os.makedirs(dir_path)\n\nos.chdir(base_dir)\n\nlr =1e-5\nos.environ[\"HUGGINGFACE_TOKEN\"] = token =  \"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\"\n\ninitial_steps = 5\nadditional_steps = 5\nnum_images = 4\ncheckpoint_prefix = \"checkpoint-\"\nupload_ckpts_to_gdrive = False\nupload_imgs_to_gdrive = True\nupload_final_ckpt_to_gdrive = True\nupload_model_to_hf = True \nupload_model_to_gdrive = False\nsave_every_checkpoint = False\nsave_final_checkpoint = True\nnumber_of_iterations = 2\nuse_gdrive_model = False\nmodel_source = \"hf\" # options are gdrive, hf \ngdrive_model_id = \"\"\nhf_model_id = \"Taa97/ZeroCool94_SDv1-5\"\nsteps_track_fpath = os.path.join(model_output_dir,\"steps_track.txt\")\ndelete_old_ckpts = True\nos.chdir(base_dir)\n\n\n\n# source is to determine where the model is going to come from ","metadata":{"executionInfo":{"elapsed":635,"status":"ok","timestamp":1726012369657,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"ocjgaNBM2iz9","execution":{"iopub.status.busy":"2024-09-21T20:19:47.068440Z","iopub.execute_input":"2024-09-21T20:19:47.068757Z","iopub.status.idle":"2024-09-21T20:19:47.089119Z","shell.execute_reply.started":"2024-09-21T20:19:47.068723Z","shell.execute_reply":"2024-09-21T20:19:47.088203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/diffusers\n!wget -q https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/requirements.txt\n!wget -q https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth.py\n!wget -q https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n!pip install -q -r requirements.txt\n!rm requirements.txt\n!pip install -q bitsandbytes\n!pip install -q gallop\n!pip install pydrive2==1.20.0 --q\n!pip install -U \"huggingface_hub[cli]\" --q","metadata":{"executionInfo":{"elapsed":37386,"status":"ok","timestamp":1726012407600,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"WtAenXz99Fez","outputId":"f74b3048-4001-41d4-c187-ed932c7ec14c","execution":{"iopub.status.busy":"2024-09-21T20:19:49.183268Z","iopub.execute_input":"2024-09-21T20:19:49.183960Z","iopub.status.idle":"2024-09-21T20:21:45.814365Z","shell.execute_reply.started":"2024-09-21T20:19:49.183894Z","shell.execute_reply":"2024-09-21T20:21:45.812857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n\nauth_data = {\n  \"type\": \"service_account\",\n  \"project_id\": \"analog-octagon-394700\",\n  \"private_key_id\": \"4763be9a634c6f76a870b590030d260cc6e30d5f\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQCZ+ZkuJTJ5NZsL\\nKyQ6tvKBMC+6Psl69AyogGWWdWYUdyeTLyrOBztLuemCv2QbBnfNU4plfSEbiXMo\\nFVo0Cywqw58sEwptke57f+BYgxHS0IxgHetFxiyek4uG7kF7ocRBYehqhlS0DPmA\\n+zK3TbG++jTT+d0xEwc+haHfBh947IgqHdw07uz2lfjwLm8OBYasiPeu/925BU4y\\nYonZkSsZaQBuKNKTxgzftm30EACiTMsvqBnRmyrTp+j0bX1V/IZNx3P17yqw/FmH\\nNxXznLTrKZmXH79cnfjF/cNqsbEeBqsI5LYSl3ZmteNVCuJSmEN2aPgrNOMZHQze\\n7x+N3wD1AgMBAAECggEAAw4xbHl/fWlDaN7Tyrh7qnWe1NbPH7n9EFDv8yLkQi61\\nIdYTRuBc3F1VlWsf3OttcC0it23avNWm69o0nojEORsFqxW7pL37GgdJF+iN732E\\n85lUZF+Q3hq2b5iFwyLMJrH/LzH4N1R0lQsnD/0iNFR5vOUd7w3eHG8BbdAMytT6\\n4y3y37HhlUKpLTYK3jYzOm1CKKcmMnB61i+sdu2eBIIhABMPoLV02molHCCmLVne\\nsQsldypAJoet1k45+FxvPt6F9UWdnY9+cmGkXHxa7vb7nC/RaDnBCt0VI/VxzmNv\\nBVOBMESYNMp5xkWDxATJq4VUFVSWf2BxNasr45MFlwKBgQDKcigdvrOuXq14VHi1\\nWAgDw5FUI+yKox/F7nQLRxtPSWh+fPNT4mrdwKMvVP6jrp2suS0QJSRJGdMT6SDy\\ns7KkK8WPQltmjhfZdlDBgTvNCAZS8AUbYLQmq5h0o4jclaiAeUp22m4jlbo4s6kB\\n73I7OGy4iMu5z20+iR9nkCQLAwKBgQDCtPDpJkLd6djdi5+pt1rULtnMs6nxPCYL\\nPA5BblKiNb5ESfmdDXbUNAovT+Ja4oyQWyaWp03G5kEGpxdWpiVY3tRbcNTYrBLb\\nOxsit7mAxlDuCb0enIJTHQdP8270QgvNsj4elmVEw6j6Tg8YSQ5GYplpI0/mdxJo\\n1qvhk3NGpwKBgA0bVPOQDCwG3y5CMcpz15j+yWLsLH1RUFZNOOAeC2uXshc2Wb6d\\nkxOmTCpdU1sfi//JwVwhO3csH9lTJ5nu/mrYlqLOxgIewvaGTXYpushsc5RdC8eY\\n/DDgvS8YA11cpxsiPyrwu168a+EN6KxCZ1/kKE3ONXpjLox07j6TO3InAoGAIDCv\\n/6vetDecLgyOag2xS5EvWwN9Hi/2jjbwmGq36K9/9GRSi1+VfMHZyTao0qPP33Hi\\ncFfaqP6aU5I+bonrdMTqUO/XkLbqKyqbcuLzHVIsQR6FENGJTlpnQhWaC3H755cH\\nZCEzPuomPrO3FSnG3WYhvNsks5KODZ0oL5QkI9MCgYB6Xa+4zwPK7Hw2EDRHAi+J\\n0iB69v0en3wuTLpXOgEnMYP+dOPoVqGig6P4ueBxG+GOnDwGihMzcRUS4gExy17r\\ndNZt2kImLSp28w4Uy+9iOn63XHDMXeBfiUC0XiZJ6g0JO3OhPsRFKDzhztog3ULv\\n+3SSXHt4/+W4KJR/da54Ow==\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"my-first-service-account@analog-octagon-394700.iam.gserviceaccount.com\",\n  \"client_id\": \"111537386863456071200\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-first-service-account%40analog-octagon-394700.iam.gserviceaccount.com\",\n  \"universe_domain\": \"googleapis.com\"\n}\n\n\nwith open(auth_json_path, 'w') as f:\n  json.dump(auth_data, f)\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\n\n\nsettings = {\n               \"client_config_backend\": \"service\",\n                \"service_config\": {\n                    \"client_json_file_path\": auth_json_path,\n                }\n            }\n\ngauth = GoogleAuth(settings=settings)\n    # Authenticate\ngauth.ServiceAuth()\n\ndrive = GoogleDrive(gauth)\n\nsubjects_info = {}\n\nsubject_ids = {\n  \"man\":\"1CqaE10_5h5jrJqt4envPRzRC9sRbA_ha\",\n  \"woman\":\"1CrIIuLilzkUX_Po2NynCxvj-KbNBkhxS\",\n  \"boy\":\"1Cr_MKDrP2oBeO9EGaAJNbs_xOjJlSWyE\",\n  \"girl\":\"1CrsFFbQFCQZupqx0lJ4gSQdnbFp1Jfnj\",\n  \"people\":\"1CskXQmCqEEMjPEBcdoxMUgLD3wKAQxql\"\n}","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1726012407601,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"w66qfyX54h3J","execution":{"iopub.status.busy":"2024-09-21T20:21:46.465636Z","iopub.execute_input":"2024-09-21T20:21:46.466086Z","iopub.status.idle":"2024-09-21T20:21:46.478014Z","shell.execute_reply.started":"2024-09-21T20:21:46.466045Z","shell.execute_reply":"2024-09-21T20:21:46.477012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def latest_steps(file_path = steps_track_fpath):\n    \"\"\"\n    Get the latest training steps.\n\n    Parameters:\n        file_path (str): Path to the file storing the training steps history.\n\n    Returns:\n        int: The latest_steps training steps\n    \"\"\"\n    # Check if the file exists\n    if not os.path.isfile(file_path):\n        return 0\n    \n    # Read the last number of training steps from the file\n    with open(file_path, 'r') as f:\n        lines = f.readlines()\n    \n    # Get the last recorded steps\n    \n    if len(lines) == 0:\n            last_steps = 0\n    else:\n        # Get the last recorded steps\n        last_steps, _ = lines[-1].strip().split(', ')\n    \n    return latest_steps\n\n\ndef record_training_steps(file_path = steps_track_fpath, additional_steps = additional_steps):\n    \"\"\"\n    Resume training by appending the new step count and date to the file.\n\n    Parameters:\n        file_path (str): Path to the file storing the training steps history.\n        additional_steps (int): The number of steps to add to the training.\n\n    Returns:\n        tuple: The new total number of training steps and the date of the update.\n    \"\"\"\n    # Check if the file exists\n    if not os.path.isfile(file_path):\n        new_steps, current_date = additional_steps, datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    \n    # Read the last number of training steps from the file\n    else:\n        with open(file_path, 'r') as f:\n            lines = f.readlines()\n\n        if len(lines) == 0:\n            last_steps = 0\n        else:\n            # Get the last recorded steps\n            last_steps, _ = lines[-1].strip().split(', ')\n        \n        # Update the step count\n        new_steps = int(last_steps) + additional_steps\n        current_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    # Append the new step count and date to the file\n    with open(file_path, 'a') as f:\n        f.write(f\"{new_steps}, {current_date}\\n\")\n\n    return new_steps, current_date","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:21:46.490413Z","iopub.execute_input":"2024-09-21T20:21:46.490773Z","iopub.status.idle":"2024-09-21T20:21:46.497272Z","shell.execute_reply.started":"2024-09-21T20:21:46.490732Z","shell.execute_reply":"2024-09-21T20:21:46.496481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\n\n# Zip the directory\ndef zip(out_put_file,zipDir):\n\n    zipf = zipfile.ZipFile(out_put_file, 'w', zipfile.ZIP_DEFLATED)\n    for root, dirs, files in os.walk(zipDir):\n        for file in files:\n            zipf.write(os.path.join(root, file),\n                       os.path.relpath(os.path.join(root, file),\n                                       os.path.join(zipDir , '..')))\n    zipf.close()\n\n\ndef unzip_directory(directory, delete = True ):\n    files = os.listdir(directory)\n\n    for file in files:\n        ext = os.path.splitext(file)[1]\n        if ext.lower() == '.zip':\n            file_path = os.path.join(directory, file)\n            output_dir = os.path.join(base_dir , 'output')\n            try:\n                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n                    zip_ref.extractall(directory)\n                if delete:\n                 os.remove(file_path)\n                return True, os.path.dirname(file_path)\n            except Exception as e:\n                return False, str(e)\n    return False, \"No zip file found\"\n\n\n\ndef get_files_by_folderid(parent_folder_id,dump_dir = class_dir):\n    for file in drive.ListFile({'q': f\"'{parent_folder_id}' in parents and trashed=false\"}).GetList():\n                if file['mimeType'].startswith('image/') or file[\"title\"].endswith(\".zip\"):\n                    file.GetContentFile(os.path.join(os.path.join(class_dir , file['title'])))\n\ndef get_actual_path(folder_path):\n\n    valid_img_exts = ['.jpg', '.jpeg', '.png', '.webp']\n\n    contents = os.listdir(folder_path)\n\n    while True:\n        if len(contents) == 0:\n            return False, f'empty folder in {folder_path} '\n        elif len(contents) == 1:\n\n            content = os.path.join(folder_path , contents[0])\n            if os.path.isdir(content):\n\n                return get_actual_path(content)\n            else:\n                ext = os.path.splitext(content)[1]\n\n                if ext.lower() == '.zip':\n                 unzip_result = unzip_directory(folder_path, delete = True)\n\n                 if unzip_result[0]:\n                  return get_actual_path(unzip_result[1])\n                 else:\n                  return unzip_result\n                if ext.lower() not in valid_img_exts:\n                    return False, f'invalid file type {ext} for {os.path.join(folder_path , content)}'\n                else:\n                    return True, folder_path\n        else:\n            for file in contents:\n                ext = os.path.splitext(file)[1]\n                if ext.lower() not in valid_img_exts:\n                    return False, f'invalid file type {ext} for {os.path.join(folder_path , file)}'\n            return True, folder_path\n\n\n\ndef get_cluster_images(cluster, count):\n  id = cluster_ids[cluster]\n  file_list = drive.ListFile({'q': f\"'{id}' in parents and trashed=false\"}).GetList()\n\n  num_files = len(file_list)\n  if num_files < count:\n    files_to_get = file_list\n  else:\n    files_to_get = random.sample(file_list, count)\n\n  for file in files_to_get:\n    file.GetContentFile(os.path.join(instance_dir, file['title']))\n\n\ndef get_finished_models(folder = model_output_dir):\n    return [f for f in os.listdir(folder) if os.path.isdir(os.path.join(folder,f)) and f.startswith(\"checkpoint-\")]\n\n\n\nimport random\n\n#download class images\nget_files_by_folderid(subject_ids[subject_class])\n\n#download instance images\nfor cluster, count in needed_images.items():\n  get_cluster_images(cluster, count)\n\n\ninstance_imgs_len = len(os.listdir(instance_dir))\n\n\nassert len(os.listdir(instance_dir)) > 0, 'instance folder can not be empty'\n\nget_actual_path_result = get_actual_path(class_dir)\nif get_actual_path_result[0]:\n class_dir =get_actual_path_result[1]\nelse:\n assert get_actual_path_result[0],get_actual_path_result[1]\n\nassert len(os.listdir(class_dir)) > 0, 'class folder can not be empty'","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1726012407601,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"oRpVInDhHfKA","execution":{"iopub.status.busy":"2024-09-21T20:21:46.509263Z","iopub.execute_input":"2024-09-21T20:21:46.509557Z","iopub.status.idle":"2024-09-21T20:21:46.528585Z","shell.execute_reply.started":"2024-09-21T20:21:46.509527Z","shell.execute_reply":"2024-09-21T20:21:46.527730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def additional_training(model_output_dir = model_output_dir,steps = 101):\n\n\n  os.environ[\"MAX_TRAINING_STEPS\"] = str(steps)\n  os.environ[\"MODEL_ID\"]  = model_output_dir\n  !accelerate launch train_dreambooth.py \\\n    --pretrained_model_name_or_path=${MODEL_ID}\\\n    --instance_data_dir=${INSTANCE_DIR}\\\n    --class_data_dir=${CLASS_DIR} \\\n    --output_dir=${OUTPUT_DIR} \\\n    --with_prior_preservation \\\n    --prior_loss_weight=1.0 \\\n    --instance_prompt=\"${INSTANCE_PROMPT}\" \\\n    --class_prompt=\"${CLASS_PROMPT}\" \\\n    --resolution=${RESOLUTION} \\\n    --train_batch_size=1 \\\n    --gradient_accumulation_steps=${GRADIENT_ACCUMULATION_STEPS}\\\n    --gradient_checkpointing \\\n    --use_8bit_adam \\\n    --learning_rate=${LEARNING_RATE} \\\n    --lr_scheduler=\"${LR_SCHEDULER}\" \\\n    --lr_warmup_steps=0 \\\n    --num_class_images=${NUM_CLASS_IMAGES} \\\n    --max_train_steps=${MAX_TRAINING_STEPS}\\\n    --checkpointing_steps=${SAVE_STARTING_STEP} \\\n    --checkpoints_total_limit=${SAVE_N_STEPS}\\\n    --resume_from_checkpoint=\"latest\"\n\n  record_training_steps(steps_track_fpath, steps)\n    \n    \ndef initial_training(model_id = hf_model_id,\n  max_train_steps =101,\n  instance_dir = instance_dir,\n  instance_prompt = instance_prompt,\n  class_prompt = class_prompt,\n  num_class_img = 100,\n  save_starting_steps=100,\n  num_of_checkpoints = 1):\n\n  os.environ[\"CLASS_DIR\"] = class_dir\n  os.environ[\"OUTPUT_DIR\"] =model_output_dir\n  os.environ[\"MODEL_NAME\"]  = model_id\n  os.environ[\"INSTANCE_DIR\"]  = instance_dir\n  os.environ[\"INSTANCE_PROMPT\"]  = instance_prompt\n  os.environ[\"CLASS_PROMPT\"] = class_prompt\n  os.environ[\"NUM_CLASS_IMAGES\"]  = str(num_class_images)\n  os.environ[\"MAX_TRAINING_STEPS\"]  = str(max_train_steps)\n  os.environ[\"SAVE_STARTING_STEP\"]  = str(save_starting_steps)\n  os.environ[\"SAVE_N_STEPS\"]  = str(num_of_checkpoints)\n  os.environ[\"MODEL_ID\"]  = model_id\n  os.environ[\"RESOLUTION\"] = str(resolution)\n  os.environ[\"LEARNING_RATE\"] = str(lr)\n  os.environ[\"GRADIENT_ACCUMULATION_STEPS\"] = str(2)\n  os.environ[\"SEED\"] = str(97)\n  os.environ[\"VAE_PATH\"] = \"madebyollin/sdxl-vae-fp16-fix\"\n  os.environ[\"LR_WARM_STEPS\"] = str(0)\n  os.environ[\"LR_SCHEDULER\"] = \"constant\"\n\n\n  !accelerate launch train_dreambooth.py \\\n    --pretrained_model_name_or_path=${MODEL_ID}\\\n    --instance_data_dir=${INSTANCE_DIR}\\\n    --class_data_dir=${CLASS_DIR} \\\n    --output_dir=${OUTPUT_DIR} \\\n    --with_prior_preservation \\\n    --prior_loss_weight=1.0 \\\n    --instance_prompt=\"${INSTANCE_PROMPT}\" \\\n    --class_prompt=\"${CLASS_PROMPT}\" \\\n    --resolution=${RESOLUTION} \\\n    --train_batch_size=1 \\\n    --gradient_accumulation_steps=${GRADIENT_ACCUMULATION_STEPS}\\\n    --gradient_checkpointing \\\n    --use_8bit_adam \\\n    --learning_rate=${LEARNING_RATE} \\\n    --lr_scheduler=\"${LR_SCHEDULER}\" \\\n    --lr_warmup_steps=0 \\\n    --num_class_images=${NUM_CLASS_IMAGES} \\\n    --max_train_steps=${MAX_TRAINING_STEPS}\\\n    --checkpointing_steps=${SAVE_STARTING_STEP} \\\n    --checkpoints_total_limit=${SAVE_N_STEPS}\n\n  record_training_steps(additional_steps = max_train_steps)","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1726012426863,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"tgnqeoFb2i0g","execution":{"iopub.status.busy":"2024-09-21T20:22:05.726470Z","iopub.execute_input":"2024-09-21T20:22:05.726939Z","iopub.status.idle":"2024-09-21T20:22:05.736616Z","shell.execute_reply.started":"2024-09-21T20:22:05.726866Z","shell.execute_reply":"2024-09-21T20:22:05.735541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NoFilesFoundError(Exception):\n    \"\"\"Custom exception for when no files are found in the folder.\"\"\"\n    pass\n\n\ndef get_latest_file(folder_path):\n    # Check if the folder exists\n    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n        latest_file = None\n        latest_time = 0\n\n        # Iterate over all files in the folder\n        for filename in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, filename)\n            # Check if it's a file\n            if os.path.isfile(file_path):\n                # Get the last modified time\n                last_modified_time = os.path.getmtime(file_path)\n                # Update the latest file if this one is more recent\n                if last_modified_time > latest_time:\n                    latest_time = last_modified_time\n                    latest_file = filename\n\n        if latest_file:\n            return os.path.join(folder_path, latest_file)\n        else:\n            raise NoFilesFoundError(\"No files found in the folder.\")\n    else:\n        raise FileNotFoundError(\"The specified folder does not exist.\")\n        \n        \ndef delete_old_checkpoints(folder_path = model_output_dir):\n    # Get a list of all folders in the directory\n    folders = os.listdir(folder_path)\n\n    # Filter the list to only include folders that start with \"checkpoint-\" followed by a number\n    checkpoint_folders = [f for f in folders if re.match(r'^checkpoint-\\d+$', f)]\n\n    # Sort the list of checkpoint folders in descending order (newest first)\n    checkpoint_folders.sort(key=lambda f: int(f.split('-')[1]), reverse=True)\n\n    # Delete all but the latest checkpoint folder\n    if len(checkpoint_folders)>1:\n\n        for f in checkpoint_folders[1:]:\n            folder_to_delete = os.path.join(folder_path, f)\n            print(f\"Deleting {folder_to_delete}\")\n            os.rmdir(folder_to_delete)\n            \n            \nfrom diffusers import StableDiffusionPipeline\nfrom transformers import CLIPTextModel\nimport torch\n\n\ndef generate_and_save_images(checkpoint_name = initial_steps, model_id = model_output_dir, img_output_dir = img_output_dir ,num_images = 4,prompt = instance_prompt, temp_img_folder = temp_img_folder):\n    # print(f\"Generating {num_images} images using model at {model_path}...\")\n\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n\n    images = []\n\n\n\n    for i in range(num_images):\n        image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n\n        img_temp_path = f\"{temp_img_folder}/{i}.png\"\n        image.save(img_temp_path)\n        images.append(image)\n\n\n    grid_path = f\"{img_output_dir}/{checkpoint_name}.png\"\n    save_image_grid(images, grid_path)\n    \n    \nfrom PIL import Image\n\ndef image_grid(imgs, rows, cols, resize=256):\n\n    if resize is not None:\n        imgs = [img.resize((resize, resize)) for img in imgs]\n    w, h = imgs[0].size\n    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n    grid_w, grid_h = grid.size\n\n    for i, img in enumerate(imgs):\n        grid.paste(img, box=(i % cols * w, i // cols * h))\n    return grid\n\n\nimport glob\ndef save_image_grid(imgs,grid_output_path):\n    # imgs = [Image.open(path) for path in glob.glob(img_paths)]\n\n    num_imgs_to_preview = 5\n    image_grid(imgs[:num_imgs_to_preview], 1, num_imgs_to_preview).save(grid_output_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:22:05.764226Z","iopub.execute_input":"2024-09-21T20:22:05.764625Z","iopub.status.idle":"2024-09-21T20:22:05.776282Z","shell.execute_reply.started":"2024-09-21T20:22:05.764581Z","shell.execute_reply":"2024-09-21T20:22:05.775175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(source = model_source,delete_ckpts = True):\n\n    if source == \"hf\":\n        download_hf_model()\n    elif source == \"gdrive\":\n        download_gdrive_model()\n\n    if not os.path.isfile(os.path.join(model_output_dir,\"model_index.json\")):\n        raise FileNotFoundError(\"model_index.json does not exist in the model directory\")\n        exit()\n    if delete_ckpts:\n        if os.path.exists(ckpt_output) and os.path.isdir(ckpt_output):\n            # Iterate over all files in the folder\n            for filename in os.listdir(ckpt_output):\n                file_path = os.path.join(ckpt_output, filename)\n                # Check if it's a file and delete it\n                if os.path.isfile(file_path):\n                    os.remove(file_path)\n\n\ndef convert_2ckpt(ckpt_basename, model_path =model_output_dir ):\n\tckpt_path = ckpt_output +\"/\"+ ckpt_basename + \".ckpt\"\n\thalf_arg = \"\"\n\n\tfp16 = True\n\tif fp16:\n\t    half_arg = \"--half\"\n\t!python convert_diffusers_to_original_stable_diffusion.py --model_path $model_path  --checkpoint_path $ckpt_path $half_arg\n\tprint(f\"[*] Converted ckpt saved at {ckpt_path}\")\n    \n    \ndef prepare2upload2hf(model_path = model_output_dir, model_ckpt_path=model_output_ckpt_folder, model_imgs_path=model_output_image_folder, ckpt_path=ckpt_output, imgs_path=img_output_dir):\n    # Check if model_path, ckpt_path, and imgs_path exist\n\n    for path in [os.path.join(model_path,\"model_index.json\"),ckpt_path,imgs_path]:\n        basename = path.split(\"/\")[-1]\n\n        if not os.path.exists(path):\n            print(f\"Error:'{basename}' does not exist.\")\n            return\n    \n    \n    # Create model_ckpt_path and model_imgs_path if they don't exist\n    os.makedirs(model_ckpt_path, exist_ok=True)\n    os.makedirs(model_imgs_path, exist_ok=True)\n\n    # Move the contents of ckpt_path to model_ckpt_path\n    for item in os.listdir(ckpt_path):\n        src_path = os.path.join(ckpt_path, item)\n        dest_path = os.path.join(model_ckpt_path, item)\n        shutil.move(src_path, dest_path)\n\n    # Move the contents of imgs_path to model_imgs_path\n    for item in os.listdir(imgs_path):\n        src_path = os.path.join(imgs_path, item)\n        dest_path = os.path.join(model_imgs_path, item)\n        shutil.move(src_path, dest_path)\n        \nfrom huggingface_hub import whoami, upload_folder, create_repo\nfrom diffusers.utils.hub_utils import load_or_create_model_card, populate_model_card\n\n\n\ndef save_model_card(\n    repo_id: str,\n    use_dora: bool,\n    images=None,\n    base_model: str = None,\n    train_text_encoder=False,\n    instance_prompt=None,\n    validation_prompt=None,\n    repo_folder=None,\n    vae_path=None,\n):\n    widget_dict = []\n    if images is not None:\n        for i, image in enumerate(images):\n            image.save(os.path.join(repo_folder, f\"image_{i}.png\"))\n            widget_dict.append(\n                {\"text\": validation_prompt if validation_prompt else \" \", \"output\": {\"url\": f\"image_{i}.png\"}}\n            )\n\n    model_description = f\"\"\"\n# {'SDXL' if 'playground' not in base_model else 'Playground'} LoRA DreamBooth - {repo_id}\n\n<Gallery />\n\n## Model description\n\nThese are {repo_id} LoRA adaption weights for {base_model}.\n\nThe weights were trained  using [DreamBooth](https://dreambooth.github.io/).\n\nLoRA for the text encoder was enabled: {train_text_encoder}.\n\nSpecial VAE used for training: {vae_path}.\n\n## Trigger words\n\nYou should use {instance_prompt} to trigger the image generation.\n\n## Download model\n\nWeights for this model are available in Safetensors format.\n\n[Download]({repo_id}/tree/main) them in the Files & versions tab.\n\nImages used = {needed_images}\n\n\n\n\"\"\"\n    if \"playground\" in base_model:\n        model_description += \"\"\"\\n\n## License\n\nPlease adhere to the licensing terms as described [here](https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic/blob/main/LICENSE.md).\n\"\"\"\n    model_card = load_or_create_model_card(\n        repo_id_or_path=repo_id,\n        from_training=True,\n        license=\"openrail++\" if \"playground\" not in base_model else \"playground-v2dot5-community\",\n        base_model=base_model,\n        prompt=instance_prompt,\n        model_description=model_description,\n        widget=widget_dict,\n    )\n    tags = [\n        \"text-to-image\",\n        \"text-to-image\",\n        \"diffusers-training\",\n        \"diffusers\",\n        \"lora\" if not use_dora else \"dora\",\n        \"template:sd-lora\",\n    ]\n    if \"playground\" in base_model:\n        tags.extend([\"playground\", \"playground-diffusers\"])\n    else:\n        tags.extend([\"stable-diffusion-xl\", \"stable-diffusion-xl-diffusers\"])\n\n    model_card = populate_model_card(model_card, tags=tags)\n    model_card.save(os.path.join(repo_folder, \"README.md\"))\n    \n    \nfrom huggingface_hub import snapshot_download\n\ndef download_hf_model(id = hf_model_id, path = model_output_dir ):\n    \n    snapshot_download(repo_id=id, local_dir =path )\n    \n    \ndef download_gdrive_model(id = gdrive_model_id):\n    if os.path.exists(model_output_dir):\n        os.rmdir(model_output_dir)\n\n    file = drive.CreateFile({\"id\":id})\n    \n    model = os.path.join(model_output_dir,\"model.zip\")\n    file.GetContentFile()\n\n    try:\n        with zipfile.ZipFile(model, 'r') as zip_ref:\n            #TODO make sure the extracted directory is not duplicated in the model directory\n            zip_ref.extractall(model_output_dir)\n        if delete:\n            os.remove(file_path)\n        return True, os.path.dirname(file_path)\n    except Exception as e:\n        return False, str(e)\n    \n","metadata":{"executionInfo":{"elapsed":651,"status":"ok","timestamp":1726013718847,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"Sr6tvHEOQu8S","execution":{"iopub.status.busy":"2024-09-21T20:22:05.813980Z","iopub.execute_input":"2024-09-21T20:22:05.814260Z","iopub.status.idle":"2024-09-21T20:22:05.823216Z","shell.execute_reply.started":"2024-09-21T20:22:05.814229Z","shell.execute_reply":"2024-09-21T20:22:05.822422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\ngc.collect()\ntorch.cuda.empty_cache()\n\n# Step 1\ncheckpoint_id = initial_steps\nnum_class_images = instance_imgs_len * 10\nresolution = 512\nmodel_path = model_output_dir\nget_model()","metadata":{"executionInfo":{"elapsed":436154,"status":"ok","timestamp":1726012878462,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"CeBKsphE55Av","outputId":"13c4151f-067b-4846-9fb8-17440f538e45","execution":{"iopub.status.busy":"2024-09-21T20:23:53.520098Z","iopub.execute_input":"2024-09-21T20:23:53.520745Z","iopub.status.idle":"2024-09-21T20:24:51.953428Z","shell.execute_reply.started":"2024-09-21T20:23:53.520705Z","shell.execute_reply":"2024-09-21T20:24:51.952373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.isfile(steps_track_fpath):\n    checkpoint_id = initial_steps\n    initial_training(model_id = model_output_dir, max_train_steps=initial_steps ,save_starting_steps=(initial_steps - 1),num_class_img = num_class_images)\n    generate_and_save_images(checkpoint_id,num_images =num_images)\n    if save_every_checkpoint:\n            convert_2ckpt(f\"{checkpoint_prefix}{checkpoint_id}\")\nelse:\n    checkpoint_id = latest_steps() ","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:26:39.565361Z","iopub.execute_input":"2024-09-21T20:26:39.565906Z","iopub.status.idle":"2024-09-21T20:28:15.387882Z","shell.execute_reply.started":"2024-09-21T20:26:39.565866Z","shell.execute_reply":"2024-09-21T20:28:15.386518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# free up some memory\ngc.collect()\ntorch.cuda.empty_cache()\n# Step 2 Loop\nfor i in range(number_of_iterations):\n    checkpoint_id += additional_steps\n\n    # Load, train, and save the new model\n    additional_training(steps = additional_steps)\n\n    # Delete the previous model\n    if delete_old_ckpts:\n        delete_old_checkpoints()\n\n    # Generate images with the new model\n    generate_and_save_images(checkpoint_id, num_images = num_images)\n\n    if save_every_checkpoint:\n        convert_2ckpt(f\"{checkpoint_prefix}{checkpoint_id}\")\n    # free up some memory\n    gc.collect()\n    torch.cuda.empty_cache()\n\nshutil.rmtree(temp_img_folder)\n\nif not save_every_checkpoint and save_final_checkpoint:\n    convert_2ckpt(f\"{checkpoint_prefix}{checkpoint_id}\")","metadata":{"id":"LVBPd65mE6wO","execution":{"iopub.status.busy":"2024-09-21T01:26:48.834256Z","iopub.status.idle":"2024-09-21T01:26:48.834744Z","shell.execute_reply.started":"2024-09-21T01:26:48.834496Z","shell.execute_reply":"2024-09-21T01:26:48.834521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if upload_imgs_to_gdrive:\n    for f in os.listdir(img_output_dir):\n        base_name = os.path.basename(f)\n        file = drive.CreateFile({'title':base_name, 'parents': [{'id': gdrive_img_output_dir }]})\n        file.SetContentFile(os.path.join(img_output_dir,f))\n        file.Upload()","metadata":{"executionInfo":{"elapsed":6810,"status":"ok","timestamp":1726013814234,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"f2cufEP_3i7j","execution":{"iopub.status.busy":"2024-09-21T01:26:48.836094Z","iopub.status.idle":"2024-09-21T01:26:48.836594Z","shell.execute_reply.started":"2024-09-21T01:26:48.836326Z","shell.execute_reply":"2024-09-21T01:26:48.836350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if upload_ckpts_to_gdrive:\n  for f in os.listdir(ckpt_output):\n    base_name = os.path.basename(f)\n    file = drive.CreateFile({'title':base_name, 'parents': [{'id': gdrive_ckpt_output_dir }]})\n    file.SetContentFile(os.path.join(ckpt_output,f))\n    file.Upload()\n    \nelse:\n    \n    if upload_final_ckpt_to_gdrive:\n        latest_file = get_latest_file(ckpt_output)\n        if latest_file:\n            base_name = os.path.basename(latest_file)\n            file = drive.CreateFile({'title':base_name, 'parents': [{'id': gdrive_ckpt_output_dir }]})\n            file.SetContentFile(latest_file)\n            file.Upload()\n            ","metadata":{"executionInfo":{"elapsed":36215,"status":"ok","timestamp":1726013854117,"user":{"displayName":"Takudzwa k","userId":"12583912603788044767"},"user_tz":-120},"id":"8CvU5Rf6QY6-","execution":{"iopub.status.busy":"2024-09-21T01:26:48.838326Z","iopub.status.idle":"2024-09-21T01:26:48.838833Z","shell.execute_reply.started":"2024-09-21T01:26:48.838574Z","shell.execute_reply":"2024-09-21T01:26:48.838598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if upload_model_to_hf:\n    prepare2upload2hf()\n    !huggingface-cli login --token ${HUGGINGFACE_TOKEN}\n    username = whoami(token=token)[\"name\"]\n    repo_id = f\"{username}/{model_id.replace('/', '-')}_{lr}_{checkpoint_id}\"\n\n    repo_id = create_repo(repo_id, exist_ok=True).repo_id\n\n    save_model_card(\n                repo_id = repo_id,\n                images=[],\n                base_model=os.getenv(\"MODEL_ID\") ,\n                train_text_encoder=False,\n                instance_prompt=os.getenv(\"INSTANCE_PROMPT\") ,\n                validation_prompt=None,\n                repo_folder=model_output_dir,\n                vae_path=os.getenv(\"VAE_PATH\")\n            )\n\n    upload_folder(\n        repo_id=repo_id,\n        folder_path=model_output_dir,\n        commit_message=\"End of training\",\n        ignore_patterns=[\"step_*\", \"epoch_*\"],\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-21T01:26:48.840418Z","iopub.status.idle":"2024-09-21T01:26:48.840949Z","shell.execute_reply.started":"2024-09-21T01:26:48.840669Z","shell.execute_reply":"2024-09-21T01:26:48.840696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if upload_model_to_gdrive:\n    final_model_zip = os.path.join(base_dir,\"model.zip\")\n    zip(final_model_zip,model_output_dir)\n    file = drive.CreateFile({'title':\"model.zip\", 'parents': [{'id': gdrive_models_output_dir }]})\n    file.SetContentFile(final_model_zip)\n    file.Upload()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T01:26:48.843497Z","iopub.status.idle":"2024-09-21T01:26:48.844070Z","shell.execute_reply.started":"2024-09-21T01:26:48.843778Z","shell.execute_reply":"2024-09-21T01:26:48.843806Z"},"trusted":true},"execution_count":null,"outputs":[]}]}